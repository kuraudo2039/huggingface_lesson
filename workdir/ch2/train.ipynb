{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af33ff97-4dd7-4a96-96fd-7dd04a76eaeb",
   "metadata": {},
   "source": [
    "# テキスト分類器の学習\n",
    "予測までの流れとして、\n",
    "\n",
    "トークンエンコーディング > トークン埋め込み > エンコーダ > 隠れ層 > 分類ヘッド > 予測\n",
    "\n",
    "となる。  \n",
    "※今までのがトークンエンコーディング  \n",
    "\n",
    "事項からは、DistilBERTで以下両方を検討し、そのトレードオフを検証する  \n",
    "- 特徴抽出\n",
    "  - 隠れ状態を特徴として利用し、分類器を学習する。事前学習済みモデルは更新しない。\n",
    "- ファインチューニング\n",
    "  - モデル全体をend-to-endで学習する。事前学習済みモデルも同時に更新する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80b1652-44e4-406c-84aa-bc037ff85c3b",
   "metadata": {},
   "source": [
    "## 特徴抽出器としてのTransformer\n",
    "\n",
    "ボディの重みを変えず、分類器のみを学習する。  \n",
    "GPUなしで素早く学習できるが、浅いモデルとなり、勾配に依存するモデルには不向き。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8701bf71-11b9-4828-a065-3b7203836df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 268M/268M [00:25<00:00, 10.4MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "# model_ckptを指定し、指定したデバイスへモデルを読み込んでいる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99bdb721-bd8e-4d35-83c2-1ebc80bfb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIPS: TensorFlowあるいはPyTorchの重みのみリリースされている場合、フレームワーク間の変換が可能\n",
    "# 以下はPyTorchのみしかリリースされていないxlm-roberta-baseをTensorFlowへ変換する例\n",
    "cache = \"\"\"\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "tf_model = TFAutoModel.from_pretrained(model_ckpt)\n",
    "tf_xlmr = TFAutoModel.from_pretrained(\"xlm-roberta-base\")\n",
    "tf_xlmr = TFAutoModel.from_pretrained(\"xlm-roberta-base\", from_pt=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4655f472-0a35-4472-9eb0-fa31173a32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93288a9e-7d95-4d37-b833-fe35233dd4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([1, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"this is a test\"\"\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "# return_tensors ... PyTorchテンソルに変換する。必須。\n",
    "\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")\n",
    "# テンソルは [batch_size, n_tokens] という形状で得られる。\n",
    "\n",
    "inputs\n",
    "# inputs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35722669-9638-4d4b-a907-3973846d7c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor([[ 101, 2023, 2003, 1037, 3231,  102]])\n",
      "attention_mask tensor([[1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "for k, v in inputs.items():\n",
    "    print(k, v)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6b58ad2-d213-4e39-8f80-dfcbb16101ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelと同じdeviceに、PyTorchテンソルを設置する。\n",
    "inputs = {k:v.to(device) for k, v in inputs.items()} # items() ... Dict型の要素をキーと値ペアの配列に変換する。順不同。\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12c266fe-45b5-4f43-99d4-d73b36d0dc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n",
       "         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n",
       "         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n",
       "         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n",
       "         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n",
       "         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]],\n",
       "       device='cuda:0'), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "outputs\n",
    "# torch.no_grad()は勾配の自動計算を無効にしている。 計算のメモリ使用量を減らす事が出来る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64382b9d-0f38-42d2-a49f-d9a2fbfadee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outputsには 隠れ状態、損失、アテンション等のオブジェクトが含まれる\n",
    "# 現在のモデルには、最後の隠れ状態である１属性のみを返す\n",
    "outputs.last_hidden_state.size()\n",
    "# [batch_size, n_tokens, hidden_dim] という形をしている。\n",
    "# ∴1バッチ、6個の入力トークン、768次元のベクトルということになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1397c42b-c6ed-424f-8ac8-4d951c81ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分類タスクの場合、入力特徴として[CLS]トークンに関連付けられた隠れ状態だけを使うのが一般的\n",
    "# これは各系列の最初に現れるので、このように抽出可能\n",
    "outputs.last_hidden_state[:, 0].size() # = [:][0]の意、配列指定の:はすべての行の取得、カンマは次元の区切りを表す。= [:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d5d71da-bc95-43b6-b3bf-00c0c9cb6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# これまでの処理をラップ\n",
    "def extract_hidden_states(batch):\n",
    "    # モデルの入力をGPU上に配置\n",
    "    inputs = {k:v.to(device) for k,v in batch.items()\n",
    "             if k in tokenizer.model_input_names} # 今回の場合、input_idsやattention_maskが含まれていることが条件\n",
    "    # 最後の隠れ状態を抽出\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state #**inputsは可変長キーワード引数を表す。input_ids, attention_maskなどのキーをまとめて渡せる。\n",
    "    # [CLS]トークンに対するベクトルを返す\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73a40c91-2bb4-4c58-b3f1-6751c237f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "emotions = load_dataset(\"dair-ai/emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39f4cb5c-fc60-4336-9d71-a40e9ee8e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3be6d9a0-bccd-47a0-aaab-c48a25d0690e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)\n",
    "emotions_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1363f4ea-7907-4385-8f5d-28dd893fd1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_ids と attension_maskの列をtorch形式に変換\n",
    "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "emotions_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee178220-3cf2-48f6-b53b-b8aca1a72b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16000/16000 [00:25<00:00, 638.98 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:02<00:00, 764.95 examples/s]\n",
      "Map: 100%|██████████| 2000/2000 [00:02<00:00, 802.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 隠れ状態を一度に抽出（予測）\n",
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)\n",
    "emotions_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fa910-7f62-47a5-b4a6-54953bef92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_hidden[\"train\"].column_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
